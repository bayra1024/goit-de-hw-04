# goit-de-hw-04


**Висновки:**

1. **Зменшення кількості Job**: На першому скріншоті видно, що виконулось 5 Job для збирання результатів (`collect`). Це відбувається тому, що при кожному виклику дії Spark виконує всю ланку обчислень від початку, якщо дані не були закешовані. 

2. **Підтримка проміжних даних в пам'яті**: Коли виконався `collect()`, виконалось 8 Job. Дані передаються з кластеру на драйвер, а всі результати зберігаються в пам'яті драйвера. Після виклику `collect()` ці дані доступні лише на локальному вузлі, і подальші трансформації (`where("count>2")`) не можуть використовувати кешовані чи вже оброблені дані в кластері.

3. **Кешування даних**: Кешування (`cache()`)дозволяє зменшити навантаження на кластер і прискорити обчислення, оскільки Spark не виконує ті самі операції кілька разів. Це покращує загальну продуктивність та ефективність виконання програм.
